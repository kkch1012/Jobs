import numpy as np
from sqlalchemy.orm import Session
from app.models.user import User
from app.models.job_post import JobPost
from app.services.similarity_scores import get_user_embedding, summarize_user_for_embedding
from sklearn.metrics.pairwise import cosine_similarity
from typing import List
import os
import requests
from app.utils.logger import recommender_logger

def get_top_n_jobs(user_embedding: np.ndarray, jobs: List[JobPost], n: int = 20) -> List[JobPost]:
    """
    ì‚¬ìš©ì ì„ë² ë”©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ Nê°œì˜ ì±„ìš© ê³µê³  ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    valid_jobs = [j for j in jobs if hasattr(j, 'full_embedding') and j.full_embedding is not None]
    if not valid_jobs:
        return []
    
    job_embeddings = np.vstack([
        np.array(j.full_embedding) if not isinstance(j.full_embedding, np.ndarray) else j.full_embedding
        for j in valid_jobs
    ])
    
    sims = cosine_similarity([user_embedding], job_embeddings)[0]
    jobs_with_sim = list(zip(valid_jobs, sims))
    jobs_with_sim.sort(key=lambda x: x[1], reverse=True)
    
    # ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ì •ë ¬ì—ë§Œ ì‚¬ìš©í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œëŠ” JobPost ê°ì²´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    return [job for job, _ in jobs_with_sim[:n]]

def make_prompt(user_summary: str, job_list: List[JobPost]) -> str:
    """LLM ì¶”ì²œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    job_str_list = [
        f"ê³µê³  ID: {job.id}\n"
        f"ì§ë¬´ëª…: {job.title}\n"
        f"ì£¼ìš” ì—…ë¬´: {job.main_tasks}\n"
        f"ìê²© ìš”ê±´: {job.qualifications}\n"
        f"ìš°ëŒ€ ì‚¬í•­: {job.preferences}\n"
        f"ê¸°ìˆ  ìŠ¤íƒ: {job.tech_stack}"
        for job in job_list
    ]
    jobs_text = "\n---\n".join(job_str_list)
    return (
        "ë‹¤ìŒì€ ì‹ ì… ë°ì´í„° ë¶„ì„ê°€ì˜ ìƒì„¸ ì´ë ¥ê³¼ ì±„ìš© ê³µê³  20ê°œì…ë‹ˆë‹¤.\n\n"
        "[ì§€ì›ì ì •ë³´]\n" + user_summary + "\n\n"
        "[ìš”ì²­ì‚¬í•­]\n"
        "- ì•„ë˜ ê³µê³  ì¤‘ í˜„ì‹¤ì ìœ¼ë¡œ ë§ì§€ ì•ŠëŠ” ì¡°ê±´(ë³‘ì—­íŠ¹ë¡€, ê²½ë ¥ ë“±)ì€ ì œì™¸\n"
        "- ìˆ™ë ¨ë„ ê¸°ì¤€ ê°€ì¤‘ì¹˜ ë°˜ì˜ (ìƒ=3, ì¤‘=2, í•˜=1)\n"
        "- ìµœì ì˜ ê³µê³  5ê°œë¥¼ ì•„ë˜ ì–‘ì‹ìœ¼ë¡œ ì¶œë ¥\n\n"
        "[ì±„ìš© ê³µê³  ëª©ë¡]\n" + jobs_text
    )

def call_qwen_api(prompt: str, api_key: str) -> str | None:
    """Qwen APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì¶”ì²œ ê²°ê³¼ ìƒì„±"""
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "X-Title": "Job Recommender"
    }
    body = {
        "model": "qwen/qwen-turbo:free",
        "messages": [
            {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ ì±„ìš© ì‹œì¥ì— ëŒ€í•´ ì˜ ì•„ëŠ” ìµœê³ ì˜ ì±„ìš© ê³µê³  ì¶”ì²œ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê³  ëª…í™•í•œ ì–´ì¡°ë¡œ ì„¤ëª…í•´ì¤˜."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.5,
        "max_tokens": 4096
    }

    try:
        response = requests.post(url, headers=headers, json=body, timeout=60)
        response.raise_for_status()
        
        response_json = response.json()
        
        choice = response_json.get("choices", [{}])[0]
        message = choice.get("message", {})
        content = message.get("content", "")

        return content if content else None

    except requests.exceptions.RequestException as e:
        recommender_logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì„œë²„ ì˜¤ë¥˜. Error: {e}")
        return None
    except (KeyError, IndexError) as e:
        recommender_logger.error(f"API ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: ì˜ˆìƒì¹˜ ëª»í•œ JSON êµ¬ì¡°. Error: {e}")
        return None
    except Exception as e:
        recommender_logger.error(f"API í˜¸ì¶œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def recommend_jobs_for_user(user: User, db: Session, api_key: str, top_n: int = 30) -> str:
    """
    ì‚¬ìš©ìì—ê²Œ ë§ì¶¤í˜• ì±„ìš©ê³µê³ ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    
    Args:
        user: ì¶”ì²œ ëŒ€ìƒ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        api_key: OpenRouter API í‚¤
        top_n: ìœ ì‚¬ë„ ìƒìœ„ Nê°œ ê³µê³ ì—ì„œ ì¶”ì²œ (ê¸°ë³¸ê°’: 30)
    
    Returns:
        ì¶”ì²œ ê²°ê³¼ ë¬¸ìì—´
    """
    jobs = db.query(JobPost).all()
    if not jobs:
        return "í˜„ì¬ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì±„ìš© ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."

    user_embedding = get_user_embedding(user)
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê³µê³  ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    top_jobs = get_top_n_jobs(user_embedding, jobs, n=top_n)

    if not top_jobs:
        return "íšŒì›ë‹˜ê³¼ ìœ ì‚¬í•œ ì±„ìš© ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    user_summary = summarize_user_for_embedding(user)
    prompt = make_prompt(user_summary, top_jobs)
    
    # LLM API í˜¸ì¶œ
    llm_recommendation = call_qwen_api(prompt, api_key)

    if llm_recommendation:
        recommender_logger.info("LLM ì¶”ì²œ ìƒì„± ì„±ê³µ")
        return llm_recommendation
    else:
        recommender_logger.warning("LLM ì¶”ì²œ ìƒì„± ì‹¤íŒ¨. ëŒ€ì²´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
        fallback_message = (
            "ğŸ¤– AI ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n"
            "ëŒ€ì‹  íšŒì›ë‹˜ì˜ ì´ë ¥ì„œì™€ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ê³µê³ ë¥¼ ìˆœì„œëŒ€ë¡œ ë³´ì—¬ë“œë¦´ê²Œìš”!\n\n"
            "--- ìœ ì‚¬ë„ ìˆœ ì¶”ì²œ ëª©ë¡ ---\n"
        )
        # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ì œì™¸í•˜ê³  íšŒì‚¬ëª…ê³¼ ì§ë¬´ëª…ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.
        for job in top_jobs[:5]:
             fallback_message += f"âœ… **{job.company_name} - {job.title}**\n"

        return fallback_message
